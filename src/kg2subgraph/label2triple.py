import os
import json
from neo4j import GraphDatabase
from typing import List, Dict, Optional
import warnings
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer, CrossEncoder
from sklearn.metrics.pairwise import cosine_similarity
import torch

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore")

class MentalHealthTreatmentFinder:
    """
    PrimeKGì—ì„œ ë‹¤ë‹¨ê³„ íƒìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    def __init__(self, uri: str = "bolt://localhost:7687", user: str = "neo4j", password: str = "dkahdkah10"):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        
        # DPR ëª¨ë¸ (Dense Passage Retrieval)
        self.dpr_model = SentenceTransformer("ncbi/MedCPT-Query-Encoder")
        
        # Cross-encoder ëª¨ë¸ (Re-ranking)
        self.cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
        
        # ì •ì‹ ê±´ê°• ê´€ë ¨ í‚¤ì›Œë“œ
        self.condition_keywords = {
            'anxiety': ['anxiety', 'anxiety disorder', 'generalized anxiety disorder', 'Panic disorder', 'social anxiety disorder', 'phobia', 'separation anxiety disorder'],
            'bipolar': ['bipolar disorder', 'cyclothymic disorder', 'Bipolar type I disorder', 'Bipolar type II disorder'],
            'depression': ['depression', 'Major depressive disorder', 'depressive disorder', 'Recurrent Depressive disorder', "Single episode depressive disorder", 'Dysthymic disorder', 'postpartum depression'],
            'Eating_disorder': ['eating disorder', 'anorexia', 'anorexia nervosa', 'bulimia nervosa', 'binge eating','feeding and eating disorder']
        }
        
        # ë¯¸ë¦¬ ê³„ì‚°ëœ evidence score ë°ì´í„° ë¡œë“œ
        self.evidence_data = self.load_evidence_data()
        
        print(f"@@ Mental Health Treatment Finder ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"@@ Evidence ë°ì´í„° ë¡œë“œ: {len(self.evidence_data)}ê°œ ì§ˆí™˜")

    def load_evidence_data(self) -> Dict:
        """
        ë¯¸ë¦¬ ê³„ì‚°ëœ evidence score ë°ì´í„°ë¥¼ ë¡œë“œ
        """
        evidence_file = "./src/kg2subgraph/test_label2triple_with_evidence.json"
        
        try:
            with open(evidence_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ì¡°ê±´ë³„ë¡œ ì •ë¦¬ëœ evidence ë°ì´í„° ìƒì„±
            evidence_dict = {}
            for condition_data in data:
                if condition_data['status'] == 'success':
                    condition = condition_data['condition']
                    evidence_dict[condition] = {}
                    
                    # ê° tripleì˜ drug nameì„ í‚¤ë¡œ í•˜ì—¬ evidence score ì €ì¥
                    for triple in condition_data['all_triples']:
                        drug_name = triple['end_node']['name']
                        evidence_dict[condition][drug_name] = {
                            'evidence_score': triple.get('evidence_score', 0.0),
                            'max_phase': triple.get('max_phase', 0.0),
                            'activity_ratio': triple.get('activity_ratio', 0.0),
                            'phase_weight': triple.get('phase_weight', 0.0),
                            'total_activities': triple.get('total_activities', 0),
                            'effective_activities': triple.get('effective_activities', 0)
                        }
            
            return evidence_dict
            
        except Exception as e:
            print(f"!! Evidence ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def close(self):
        self.driver.close()

    def find_condition_start_nodes(self, condition: str) -> List[Dict]:
        if condition not in self.condition_keywords:
            print(f"X ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§ˆí™˜: {condition}")
            return []
            
        keywords = self.condition_keywords[condition]
        print(f"@@ '{condition}' ê´€ë ¨ ì‹œì‘ ë…¸ë“œ ê²€ìƒ‰ ì¤‘...")
        
        with self.driver.session(database="neo4j") as session:
            keyword_conditions = " OR ".join([
                f"toLower(n.name) CONTAINS toLower('{keyword}')" for keyword in keywords
            ])
            
            query = f"""
            MATCH (n:Node {{type: 'disease'}})
            WHERE n.name IS NOT NULL AND ({keyword_conditions})
            RETURN DISTINCT n.id AS id, n.name AS name
            LIMIT 20
            """
            
            result = session.run(query)
            nodes = [{'id': record['id'], 'name': record['name']} for record in result]
            
            if not nodes:
                print(f"X '{condition}' ê´€ë ¨ ì‹œì‘ ë…¸ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            print(f"@@ {len(nodes)}ê°œì˜ ì ì¬ì  ì‹œì‘ ë…¸ë“œ ë°œê²¬")
            return nodes

    def collect_treatment_triples(self, condition: str, start_nodes: List[Dict]) -> List[Dict]:
        if not start_nodes:
            return []
            
        print(f"ğŸ”— {len(start_nodes)}ê°œ ì‹œì‘ ë…¸ë“œë¡œë¶€í„° ì¹˜ë£Œ ê´€ê³„ íƒìƒ‰ ì‹œì‘...")
        
        all_triples = []
        start_node_ids = [node['id'] for node in start_nodes]
        
        with self.driver.session(database="neo4j") as session:
            # indicationê³¼ off-label use ê´€ê³„ë§Œ ê²€ìƒ‰
            query = """
            MATCH (start:Node)-[r:RELATES]->(treatment:Node {type: 'drug'})
            WHERE start.id IN $start_node_ids AND r.type IN ['indication', 'off-label use']
            RETURN start.name AS start_name, r.type AS rel_type, treatment.name AS end_name, treatment.type AS end_type
            """
            result = session.run(query, start_node_ids=start_node_ids)
            for record in result:
                all_triples.append({
                    'start_node': {'name': record['start_name'], 'type': 'disease'},
                    'relation': record['rel_type'],
                    'end_node': {'name': record['end_name'], 'type': record['end_type']},
                    'priority': 1
                })
        
        # ì¤‘ë³µ ì œê±°
        seen = set()
        unique_triples = []
        for triple in all_triples:
            key = (triple['start_node']['name'], triple['relation'], triple['end_node']['name'])
            if key not in seen:
                unique_triples.append(triple)
                seen.add(key)

        print(f"(ì•½ë¬¼) ì´ {len(unique_triples)}ê°œì˜ ìœ ë‹ˆí¬í•œ ì¹˜ë£Œ ê´€ë ¨ Triple ìˆ˜ì§‘ ì™„ë£Œ")
        
        # ë¯¸ë¦¬ ê³„ì‚°ëœ evidence score ì •ë³´ ì¶”ê°€
        if condition in self.evidence_data:
            for triple in unique_triples:
                drug_name = triple['end_node']['name']
                if drug_name in self.evidence_data[condition]:
                    evidence_info = self.evidence_data[condition][drug_name]
                    triple.update(evidence_info)
                    print(f"ğŸ“Š {drug_name}: Evidence score({evidence_info['evidence_score']:.3f})")
                else:
                    # Evidence ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                    triple.update({
                        'evidence_score': 0.0,
                        'max_phase': 0.0,
                        'activity_ratio': 0.0,
                        'phase_weight': 0.0,
                        'total_activities': 0,
                        'effective_activities': 0
                    })
                    print(f"!! {drug_name}: Evidence ë°ì´í„° ì—†ìŒ (ê¸°ë³¸ê°’ 0.0 ì‚¬ìš©)")
        else:
            print(f"!! '{condition}' ì§ˆí™˜ì˜ evidence ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # ëª¨ë“  tripleì— ê¸°ë³¸ê°’ ì„¤ì •
            for triple in unique_triples:
                triple.update({
                    'evidence_score': 0.0,
                    'max_phase': 0.0,
                    'activity_ratio': 0.0,
                    'phase_weight': 0.0,
                    'total_activities': 0,
                    'effective_activities': 0
                })
        
        return unique_triples

    def get_treatment_recommendation(self, condition: str, user_query: str) -> Dict:
        print(f"\n@@ '{condition.upper()}' ì¹˜ë£Œë²• ì¶”ì²œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print(f"@@ ì¿¼ë¦¬: '{user_query[:100]}...'")
        print("="*60)
        
        start_nodes = self.find_condition_start_nodes(condition)

        if not start_nodes:
            return {'status': 'no_start_nodes', 'message': f"'{condition}'ì— í•´ë‹¹í•˜ëŠ” ì§ˆë³‘ ë…¸ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
        
        triples = self.collect_treatment_triples(condition, start_nodes)
        if not triples:
            return {'status': 'no_triples', 'message': "ê´€ë ¨ëœ ì¹˜ë£Œë²• ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
        
        # BM25 + DPR + Cross-encoder + Evidence supportë¥¼ ì‚¬ìš©í•œ triple ì„ ì •
        selected_triple = self.select_best_triples_with_retrieval(user_query, triples)
        
        if not selected_triple:
            return {'status': 'no_selected_triples', 'message': "ì‚¬ìš©ì ì¿¼ë¦¬ì™€ ê´€ë ¨ì„± ë†’ì€ ì¹˜ë£Œë²•ì„ ì„ ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
        
        result = {
            'status': 'success',
            'condition': condition,
            'user_query': user_query,
            'all_triples': triples,
            'selected_triple': selected_triple,
            'total_triples_found': len(triples),
            'selected_count': 1,
            'summary': f"'{condition}' ì§ˆí™˜ì— ëŒ€í•´ ì´ {len(triples)}ê°œì˜ ì¹˜ë£Œë²• ê´€ë ¨ tripleì„ ì°¾ì•˜ê³ , ê·¸ ì¤‘ 1ê°œë¥¼ ì„ ë³„í–ˆìŠµë‹ˆë‹¤."
        }
        
        print(f"@@ ê²°ê³¼: {result['summary']}")
        print("="*60)
        
        return result

    def convert_triples_to_sentences(self, triples: List[Dict]) -> List[str]:
        """
        Tripleë“¤ì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
        """
        sentences = []
        for triple in triples:
            disease = triple['start_node']['name']
            relation = triple['relation']
            treatment = triple['end_node']['name']
            
            if relation == 'indication':
                sentence = f"{treatment} is an indication for {disease}"
            elif relation == 'off-label use':
                sentence = f"{treatment} is used off-label for {disease}"
            else:
                sentence = f"{disease} {relation} {treatment}"
            
            sentences.append(sentence)
        
        return sentences

    def bm25_retrieval(self, query: str, sentences: List[str], top_k: int = 10) -> List[int]:
        """
        BM25ë¥¼ ì‚¬ìš©í•œ sparse retrieval
        """
        # í† í°í™” (ê°„ë‹¨í•œ ê³µë°± ê¸°ë°˜)
        tokenized_sentences = [sentence.lower().split() for sentence in sentences]
        tokenized_query = query.lower().split()
        
        # BM25 ëª¨ë¸ ìƒì„±
        bm25 = BM25Okapi(tokenized_sentences)
        
        # ê²€ìƒ‰ ì‹¤í–‰
        scores = bm25.get_scores(tokenized_query)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ë°˜í™˜
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        return top_indices.tolist()

    def dpr_retrieval(self, query: str, sentences: List[str], top_k: int = 10) -> List[int]:
        """
        DPRì„ ì‚¬ìš©í•œ dense retrieval
        """
        # Queryì™€ sentencesë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_embedding = self.dpr_model.encode([query])
        sentence_embeddings = self.dpr_model.encode(sentences)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(query_embedding, sentence_embeddings)[0]
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ë°˜í™˜
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        return top_indices.tolist()

    def cross_encoder_reranking(self, query: str, sentences: List[str], candidate_indices: List[int], top_k: int = 5) -> List[Dict]:
        """
        Cross-encoderë¥¼ ì‚¬ìš©í•œ re-ranking
        """
        # í›„ë³´ ë¬¸ì¥ë“¤ ì¤€ë¹„
        candidate_sentences = [sentences[i] for i in candidate_indices]
        
        # Query-sentence ìŒ ìƒì„±
        query_sentence_pairs = [[query, sentence] for sentence in candidate_sentences]
        
        # Cross-encoderë¡œ relevance score ê³„ì‚°
        scores = self.cross_encoder.predict(query_sentence_pairs)
        
        # ì ìˆ˜ì™€ ì¸ë±ìŠ¤ë¥¼ í•¨ê»˜ ì •ë ¬
        scored_candidates = [
            {
                'index': candidate_indices[i],
                'sentence': candidate_sentences[i],
                'relevance_score': float(scores[i])
            }
            for i in range(len(candidate_indices))
        ]
        
        # relevance score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        scored_candidates.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        return scored_candidates[:top_k]

    def select_best_triples_with_retrieval(self, user_query: str, triples: List[Dict]) -> Dict:
        """
        BM25 + DPR + Cross-encoder + ë¯¸ë¦¬ ê³„ì‚°ëœ Evidence scoreë¥¼ ì‚¬ìš©í•œ ìµœì  triple 1ê°œ ì„ ì •
        """
        if not triples:
            return None
        
        print(f"ğŸ” Triple ì„ ì • ì‹œì‘: {len(triples)}ê°œ í›„ë³´ â†’ BM25 + DPR + Cross-encoder + Evidence â†’ ìµœì¢… 1ê°œ ì„ ì •")
        
        # 1ë‹¨ê³„: Tripleì„ ìì—°ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
        sentences = self.convert_triples_to_sentences(triples)
        print(f"{len(sentences)}ê°œ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ")
        
        # 2ë‹¨ê³„: BM25 retrieval (ìƒìœ„ 20ê°œ)
        bm25_candidates = self.bm25_retrieval(user_query, sentences, top_k=min(20, len(sentences)))
        print(f"BM25 í›„ë³´: {len(bm25_candidates)}ê°œ")
        
        # 3ë‹¨ê³„: DPR retrieval (ìƒìœ„ 20ê°œ)
        dpr_candidates = self.dpr_retrieval(user_query, sentences, top_k=min(20, len(sentences)))
        print(f"DPR í›„ë³´: {len(dpr_candidates)}ê°œ")
        
        # 4ë‹¨ê³„: ë‘ ë°©ë²•ì˜ í›„ë³´ë¥¼ í•©ì¹˜ê³  ì¤‘ë³µ ì œê±°
        combined_candidates = list(set(bm25_candidates + dpr_candidates))
        print(f"í†µí•© í›„ë³´: {len(combined_candidates)}ê°œ")
        
        # 5ë‹¨ê³„: Cross-encoder re-ranking (ìƒìœ„ 5ê°œë§Œ ê³„ì‚°)
        reranked_results = self.cross_encoder_reranking(
            user_query, sentences, combined_candidates, top_k=5
        )
        print(f"@@ Re-ranking ì™„ë£Œ: ìƒìœ„ 5ê°œ í›„ë³´")
        
        # 6ë‹¨ê³„: ë¯¸ë¦¬ ê³„ì‚°ëœ Evidence scoreì™€ Relevance score í•©ì‚°í•˜ì—¬ ìµœì¢… ì ìˆ˜ ê³„ì‚°
        print(f"@@ ìµœì¢… ì ìˆ˜ ê³„ì‚°: Relevance Score + Evidence Score")
        
        for result in reranked_results:
            triple_idx = result['index']
            triple = triples[triple_idx]
            
            # ë¯¸ë¦¬ ê³„ì‚°ëœ evidence score ê°€ì ¸ì˜¤ê¸°
            evidence_score = triple.get('evidence_score', 0.0)
            
            # ìµœì¢… ì ìˆ˜ = relevance_score + evidence_score
            final_score = result['relevance_score'] + evidence_score
            
            result['evidence_score'] = evidence_score
            result['final_score'] = final_score
            
            print(f"  ğŸ“Š {triple['end_node']['name']}: "
                  f"Relevance({result['relevance_score']:.3f}) + "
                  f"Evidence({evidence_score:.3f}) = "
                  f"Final({final_score:.3f})")
        
        # 7ë‹¨ê³„: ìµœì¢… ì ìˆ˜ë¡œ ì¬ì •ë ¬
        reranked_results.sort(key=lambda x: x['final_score'], reverse=True)
        
        # 8ë‹¨ê³„: ìµœì¢… 1ê°œ ì„ ì •
        if not reranked_results:
            return None
            
        best_result = reranked_results[0]
        
        # ì›ë³¸ tripleê³¼ ì„ ì • ê¸°ì¤€ ì •ë³´ë¥¼ í•¨ê»˜ ë°˜í™˜
        final_triple = triples[best_result['index']].copy()
        final_triple['relevance_score'] = best_result['relevance_score']
        final_triple['final_score'] = best_result['final_score']
        final_triple['natural_sentence'] = best_result['sentence']
        
        # ì„ ì • ê¸°ì¤€ ì •ë³´ ì¶”ê°€
        selection_criteria = {
            'method': 'BM25 + DPR + Cross-encoder + Pre-calculated Evidence Score',
            'total_candidates': len(triples),
            'bm25_candidates': len(bm25_candidates),
            'dpr_candidates': len(dpr_candidates),
            'combined_candidates': len(combined_candidates),
            'cross_encoder_score': best_result['relevance_score'],
            'evidence_score': best_result['evidence_score'],
            'final_combined_score': best_result['final_score'],
            'ranking_position': 1,
            'selection_reason': f"ìµœì¢… ì ìˆ˜ ({best_result['final_score']:.4f}) = Relevance({best_result['relevance_score']:.3f}) + Evidence({best_result['evidence_score']:.3f})"
        }
        
        final_triple['selection_criteria'] = selection_criteria
        
        print(f"@@ ìµœì¢… ì„ ì •: '{final_triple['end_node']['name']}' (ìµœì¢…ì ìˆ˜: {best_result['final_score']:.4f})")
        print(f"@@ ì„ ì • ê¸°ì¤€: {selection_criteria['selection_reason']}")
        print(f"@@ Evidence ìƒì„¸: Phase({final_triple.get('max_phase', 0):.1f}), "
              f"Activities({final_triple.get('effective_activities', 0)}/{final_triple.get('total_activities', 0)}), "
              f"Activity_ratio({final_triple.get('activity_ratio', 0):.3f})")
        
        return final_triple


# íŒŒì´í”„ë¼ì¸ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ ì¸í„°í˜ì´ìŠ¤ ì¶”ê°€
def get_treatment_triple_from_condition(condition: str, user_query: str, 
                                      neo4j_uri: str = "bolt://localhost:7687", 
                                      neo4j_user: str = "neo4j", 
                                      neo4j_password: str = "dkahdkah10") -> Dict:
    """
    íŒŒì´í”„ë¼ì¸ì—ì„œ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜
    íŠ¹ì • ì§ˆí™˜ê³¼ ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•œ ì¹˜ë£Œë²• Tripleì„ ë°˜í™˜
    """
    finder = MentalHealthTreatmentFinder(uri=neo4j_uri, user=neo4j_user, password=neo4j_password)
    
    try:
        result = finder.get_treatment_recommendation(condition, user_query)
        
        # ê²°ê³¼ í¬ë§·ì„ pipelineì— ë§ê²Œ ì¡°ì •
        if result['status'] == 'success':
            selected_triple = result['selected_triple']
            
            # summary ì •ë³´ ì¶”ê°€
            result['summary'] = {
                'selected_treatment': selected_triple['end_node']['name'],
                'selected_start_node': selected_triple['start_node']['name'],
                'relation': selected_triple['relation'],
                'final_score': selected_triple.get('final_score', 0.0),
                'relevance_score': selected_triple.get('relevance_score', 0.0),
                'evidence_score': selected_triple.get('evidence_score', 0.0)
            }
        
        return result
        
    except Exception as e:
        return {
            'status': 'error',
            'message': f"Error processing {condition}: {str(e)}",
            'condition': condition,
            'user_query': user_query
        }
    finally:
        finder.close()


def main():
    NEO4J_URI = os.environ.get("NEO4J_URI", "bolt://localhost:7687")
    NEO4J_USER = os.environ.get("NEO4J_USER", "neo4j")
    NEO4J_PASSWORD = os.environ.get("NEO4J_PASSWORD", "dkahdkah10")

    finder = MentalHealthTreatmentFinder(uri=NEO4J_URI, user=NEO4J_USER, password=NEO4J_PASSWORD)

    try:
        test_cases = {
            'depression': "I'm suffering from major depression and feel hopeless. What treatment options are available?",
            'anxiety': "I have been experiencing severe anxiety and panic attacks lately. What treatments would be most effective?",
            'bipolar': "I have bipolar disorder with manic episodes. What medication can help stabilize my mood?",
            'Eating_disorder': "I have anorexia nervosa and can't stop restricting food. What treatments can help?"
        }
        
        all_results = []
        
        # ê° ì§ˆí™˜ë³„ë¡œ ì¹˜ë£Œë²• ì¶”ì²œ
        for condition, query in test_cases.items():
            print(f"\n{'='*80}")
            print(f"ì²˜ë¦¬ ì¤‘: {condition}")
            print(f"{'='*80}")
            
            result = finder.get_treatment_recommendation(condition, query)
            all_results.append(result)
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        output_dir = "./output_dir"
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, "test_final_recommendations.json")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        
        # ì „ì²´ í†µê³„ ì¶œë ¥
        print(f"\n{'='*80}")
        print("@@ ì „ì²´ ê²°ê³¼ ìš”ì•½:")
        print(f"{'='*80}")
        
        for i, result in enumerate(all_results):
            condition = list(test_cases.keys())[i]
            if result['status'] == 'success':
                selected_triple = result['selected_triple']
                treatment_name = selected_triple['end_node']['name']
                final_score = selected_triple['final_score']
                relevance_score = selected_triple['relevance_score']
                evidence_score = selected_triple.get('evidence_score', 0.0)
                
                print(f"** {condition:15}: {treatment_name} "
                      f"(Final: {final_score:.3f} = Rel: {relevance_score:.3f} + Evi: {evidence_score:.3f})")
            else:
                print(f"X {condition:15}: ì¶”ì²œ ì‹¤íŒ¨")
        
        print(f"\n@@ ìµœì¢… ì¶”ì²œ ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"X ë©”ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        finder.close()
        print("\n** íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ.")


if __name__ == "__main__":
    main()
